{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-cno5GsQ9my",
        "outputId": "cf915698-2034-4e73-aa41-fe2cf2c6be73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analytical Solution:\n",
            "b0: 1.2363636363636363, b1: 1.1696969696969697\n",
            "SSE: 5.624242424242423, R²: 0.952538038613988\n",
            "\n",
            "Full-batch Gradient Descent:\n",
            "b0: 1.2328099487610318, b1: 1.170263693076768\n",
            "SSE: 5.624278989977716, R²: 0.9525377300423822\n",
            "\n",
            "Stochastic Gradient Descent:\n",
            "b0: 0.8967040680508923, b1: 1.2986755729435908\n",
            "SSE: 7.576246971879953, R²: 0.9360654263976376\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])\n",
        "\n",
        "# Analytical solution\n",
        "def analytical_solution(x, y):\n",
        "    n = len(x)\n",
        "    x_mean = np.mean(x)\n",
        "    y_mean = np.mean(y)\n",
        "\n",
        "    # Calculate the coefficients\n",
        "    b1 = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean) ** 2)\n",
        "    b0 = y_mean - b1 * x_mean\n",
        "\n",
        "    return b0, b1\n",
        "\n",
        "# Predict function\n",
        "def predict(x, b0, b1):\n",
        "    return b0 + b1 * x\n",
        "\n",
        "# Sum of Squared Errors (SSE)\n",
        "def calculate_sse(y_true, y_pred):\n",
        "    return np.sum((y_true - y_pred) ** 2)\n",
        "\n",
        "# Coefficient of Determination (R²)\n",
        "def calculate_r2(y_true, y_pred):\n",
        "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
        "    return 1 - (ss_residual / ss_total)\n",
        "\n",
        "# Full-batch Gradient Descent\n",
        "def full_batch_gradient_descent(x, y, alpha=0.01, epochs=1000):\n",
        "    m = len(y)\n",
        "    b0 = b1 = 0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        y_pred = b0 + b1 * x\n",
        "        d_b0 = -(2/m) * np.sum(y - y_pred)\n",
        "        d_b1 = -(2/m) * np.sum((y - y_pred) * x)\n",
        "        b0 -= alpha * d_b0\n",
        "        b1 -= alpha * d_b1\n",
        "\n",
        "    return b0, b1\n",
        "\n",
        "# Stochastic Gradient Descent\n",
        "def stochastic_gradient_descent(x, y, alpha=0.01, epochs=1000):\n",
        "    m = len(y)\n",
        "    b0 = b1 = 0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for i in range(m):\n",
        "            y_pred = b0 + b1 * x[i]\n",
        "            d_b0 = -(2) * (y[i] - y_pred)\n",
        "            d_b1 = -(2) * (y[i] - y_pred) * x[i]\n",
        "            b0 -= alpha * d_b0\n",
        "            b1 -= alpha * d_b1\n",
        "\n",
        "    return b0, b1\n",
        "\n",
        "# Compute regression coefficients using analytical solution\n",
        "b0_analytical, b1_analytical = analytical_solution(x, y)\n",
        "y_pred_analytical = predict(x, b0_analytical, b1_analytical)\n",
        "\n",
        "# Compute SSE and R² for analytical solution\n",
        "sse_analytical = calculate_sse(y, y_pred_analytical)\n",
        "r2_analytical = calculate_r2(y, y_pred_analytical)\n",
        "\n",
        "# Compute regression coefficients using Full-batch Gradient Descent\n",
        "b0_full_gd, b1_full_gd = full_batch_gradient_descent(x, y)\n",
        "y_pred_full_gd = predict(x, b0_full_gd, b1_full_gd)\n",
        "\n",
        "# Compute SSE and R² for Full-batch Gradient Descent\n",
        "sse_full_gd = calculate_sse(y, y_pred_full_gd)\n",
        "r2_full_gd = calculate_r2(y, y_pred_full_gd)\n",
        "\n",
        "# Compute regression coefficients using Stochastic Gradient Descent\n",
        "b0_sgd, b1_sgd = stochastic_gradient_descent(x, y)\n",
        "y_pred_sgd = predict(x, b0_sgd, b1_sgd)\n",
        "\n",
        "# Compute SSE and R² for Stochastic Gradient Descent\n",
        "sse_sgd = calculate_sse(y, y_pred_sgd)\n",
        "r2_sgd = calculate_r2(y, y_pred_sgd)\n",
        "\n",
        "print(\"Analytical Solution:\")\n",
        "print(f\"b0: {b0_analytical}, b1: {b1_analytical}\")\n",
        "print(f\"SSE: {sse_analytical}, R²: {r2_analytical}\\n\")\n",
        "\n",
        "print(\"Full-batch Gradient Descent:\")\n",
        "print(f\"b0: {b0_full_gd}, b1: {b1_full_gd}\")\n",
        "print(f\"SSE: {sse_full_gd}, R²: {r2_full_gd}\\n\")\n",
        "\n",
        "print(\"Stochastic Gradient Descent:\")\n",
        "print(f\"b0: {b0_sgd}, b1: {b1_sgd}\")\n",
        "print(f\"SSE: {sse_sgd}, R²: {r2_sgd}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the path to the dataset in the Downloads folder\n",
        "dataset_path = '/content/BostonHousing.csv'  # Adjust the file path if necessary\n",
        "\n",
        "# Load dataset from file\n",
        "data = pd.read_csv(dataset_path)\n",
        "data.head()\n",
        "# Input Data (X)\n",
        "X_input = data.drop(columns='medv')  # Assuming 'medv' is the target column\n",
        "\n",
        "# Output Data (y)\n",
        "y_output = data['medv']  # Target variable\n",
        "\n",
        "# Analyzing Correlations\n",
        "correlations = X_input.corrwith(y_output)\n",
        "\n",
        "# Print the correlation values for all attributes\n",
        "print(\"Correlation of each attribute with the target variable (medv):\")\n",
        "for attribute, correlation_value in correlations.items():\n",
        "    print(f\"{attribute}: {correlation_value:.4f}\")\n",
        "\n",
        "# Identify the attribute with the highest correlation to the target variable\n",
        "best_attribute = (correlations**2).idxmax()\n",
        "print(f\"\\nAttribute with the highest correlation to medv: {best_attribute}, Correlation: {correlations.abs().max():.4f}\")\n",
        "\n",
        "# Selecting the best attribute for Linear Regression\n",
        "x = X_input[[best_attribute]].values.flatten()\n",
        "y = y_output.values\n",
        "\n",
        "\n",
        "# Analytical solution\n",
        "def analytical_solution(x, y):\n",
        "    n = len(x)\n",
        "    x_mean = np.mean(x)\n",
        "    y_mean = np.mean(y)\n",
        "\n",
        "    # Calculate the coefficients\n",
        "    b1 = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean) ** 2)\n",
        "    b0 = y_mean - b1 * x_mean\n",
        "\n",
        "    return b0, b1\n",
        "\n",
        "# Predict function\n",
        "def predict(x, b0, b1):\n",
        "    return b0 + b1 * x\n",
        "\n",
        "# Sum of Squared Errors (SSE)\n",
        "def calculate_sse(y_true, y_pred):\n",
        "    return np.sum((y_true - y_pred) ** 2)\n",
        "\n",
        "# Coefficient of Determination (R²)\n",
        "def calculate_r2(y_true, y_pred):\n",
        "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
        "    return 1 - (ss_residual / ss_total)\n",
        "\n",
        "\n",
        "def full_batch_gradient_descent(x, y, alpha=0.001, epochs=10000):\n",
        "    m = len(y)\n",
        "    b0 = b1 = 0\n",
        "    for _ in range(epochs):\n",
        "        y_pred = b0 + b1 * x\n",
        "        d_b0 = -(2/m) * np.sum(y - y_pred)\n",
        "        d_b1 = -(2/m) * np.sum((y - y_pred) * x)\n",
        "        b0 -= alpha * d_b0\n",
        "        b1 -= alpha * d_b1\n",
        "    return b0, b1\n",
        "\n",
        "def stochastic_gradient_descent(x, y, alpha=0.00001, epochs=1000):\n",
        "    m = len(y)\n",
        "    b0 = b1 = 0\n",
        "    for _ in range(epochs):\n",
        "        for i in range(m):\n",
        "            y_pred = b0 + b1 * x[i]\n",
        "            d_b0 = -(2) * (y[i] - y_pred)\n",
        "            d_b1 = -(2) * (y[i] - y_pred) * x[i]\n",
        "            b0 -= alpha * d_b0\n",
        "            b1 -= alpha * d_b1\n",
        "    return b0, b1\n",
        "\n",
        "\n",
        "# Compute regression coefficients using analytical solution\n",
        "b0_analytical, b1_analytical = analytical_solution(x, y)\n",
        "y_pred_analytical = predict(x, b0_analytical, b1_analytical)\n",
        "\n",
        "# Compute SSE and R² for analytical solution\n",
        "sse_analytical = calculate_sse(y, y_pred_analytical)\n",
        "r2_analytical = calculate_r2(y, y_pred_analytical)\n",
        "\n",
        "# Compute regression coefficients using Full-batch Gradient Descent\n",
        "b0_full_gd, b1_full_gd = full_batch_gradient_descent(x, y)\n",
        "y_pred_full_gd = predict(x, b0_full_gd, b1_full_gd)\n",
        "\n",
        "# Compute SSE and R² for Full-batch Gradient Descent\n",
        "sse_full_gd = calculate_sse(y, y_pred_full_gd)\n",
        "r2_full_gd = calculate_r2(y, y_pred_full_gd)\n",
        "\n",
        "# Compute regression coefficients using Stochastic Gradient Descent\n",
        "b0_sgd, b1_sgd = stochastic_gradient_descent(x, y)\n",
        "y_pred_sgd = predict(x, b0_sgd, b1_sgd)\n",
        "\n",
        "# Compute SSE and R² for Stochastic Gradient Descent\n",
        "sse_sgd = calculate_sse(y, y_pred_sgd)\n",
        "r2_sgd = calculate_r2(y, y_pred_sgd)\n",
        "\n",
        "# Display results\n",
        "print(\"Analytical Solution:\")\n",
        "print(f\"b0: {b0_analytical}, b1: {b1_analytical}\")\n",
        "print(f\"SSE: {sse_analytical}, R²: {r2_analytical}\\n\")\n",
        "\n",
        "print(\"Full-batch Gradient Descent:\")\n",
        "print(f\"b0: {b0_full_gd}, b1: {b1_full_gd}\")\n",
        "print(f\"SSE: {sse_full_gd}, R²: {r2_full_gd}\\n\")\n",
        "\n",
        "print(\"Stochastic Gradient Descent:\")\n",
        "print(f\"b0: {b0_sgd}, b1: {b1_sgd}\")\n",
        "print(f\"SSE: {sse_sgd}, R²: {r2_sgd}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArsCDzz6WvW5",
        "outputId": "22d13cb5-2c80-4227-d176-e01ad96d2e35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation of each attribute with the target variable (medv):\n",
            "crim: -0.3883\n",
            "zn: 0.3604\n",
            "indus: -0.4837\n",
            "chas: 0.1753\n",
            "nox: -0.4273\n",
            "rm: 0.6962\n",
            "age: -0.3770\n",
            "dis: 0.2499\n",
            "rad: -0.3816\n",
            "tax: -0.4685\n",
            "ptratio: -0.5078\n",
            "b: 0.3335\n",
            "lstat: -0.7377\n",
            "\n",
            "Attribute with the highest correlation to medv: lstat, Correlation: 0.7377\n",
            "Analytical Solution:\n",
            "b0: 34.5538408793831, b1: -0.9500493537579907\n",
            "SSE: 19472.38141832644, R²: 0.5441462975864797\n",
            "\n",
            "Full-batch Gradient Descent:\n",
            "b0: 34.27230357706076, b1: -0.9331466362919295\n",
            "SSE: 19482.055739702933, R²: 0.5439198191130424\n",
            "\n",
            "Stochastic Gradient Descent:\n",
            "b0: 31.445323966159428, b1: -0.798183438613218\n",
            "SSE: 20779.190257821538, R²: 0.5135535500928476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6uwHhdHWwVA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}